{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 4661 Project: Poker Rule Induction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing dataset.\n",
    "#df = pd.read_csv('train.csv')\n",
    "#dataset with additional hands of straights to royal flushes. \n",
    "    #Comment out above, and uncomment the below to use this data set.\n",
    "df = pd.read_csv('train_adjusted.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy using KNN with Cross Validation, Logistical Regression with Cross Validation, and Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into training and test sets.\n",
    "feature_cols = ['S1', 'C1', 'S2', 'C2', 'S3', 'C3', 'S4', 'C4', 'S5', 'C5']\n",
    "\n",
    "X = df[feature_cols]\n",
    "y = df['hand']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\sklearn\\model_selection\\_split.py:657: Warning: The least populated class in y has only 8 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5790070178721511\n"
     ]
    }
   ],
   "source": [
    "#KNN\n",
    "#The data set does not contain enough of some of the top end hands, which is the reason for the error.\n",
    "knn = KNeighborsClassifier(n_neighbors=30)\n",
    "knn_accuracy_list = cross_val_score(knn, X, y, cv=10, scoring='accuracy')\n",
    "knn_accuracy_cv = knn_accuracy_list.mean()\n",
    "print(knn_accuracy_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\sklearn\\model_selection\\_split.py:657: Warning: The least populated class in y has only 8 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49683915127641276\n"
     ]
    }
   ],
   "source": [
    "#Logistical Regression\n",
    "#The data set does not contain enough of some of the top end hands, which is the reason for the error.\n",
    "logreg = LogisticRegression(multi_class='auto', solver='liblinear')\n",
    "logreg_accuracy_list = cross_val_score(logreg, X, y, cv=10, scoring = 'accuracy')\n",
    "logreg_accuracy_cv = logreg_accuracy_list.mean()\n",
    "print(logreg_accuracy_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5470272419964207\n"
     ]
    }
   ],
   "source": [
    "#Random Forest with 70% of the data set as the training set.\n",
    "rf = RandomForestClassifier(n_estimators=10, random_state=10)\n",
    "rf.fit(X_train, y_train.values.ravel())\n",
    "rf_y_pred = rf.predict(X_test)\n",
    "rf_accuracy = accuracy_score(rf_y_pred, y_test)\n",
    "print(rf_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding additional features to dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding the 'flush' feature.\n",
    "flush = [0]*len(df['S1'])\n",
    "\n",
    "for i in range(len(df['S1'])):     \n",
    "    if df['S1'][i] == df['S2'][i] == df['S3'][i] == df['S4'][i] == df['S5'][i]:\n",
    "        flush[i] = 1\n",
    "\n",
    "df['flush'] = flush"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding pair, triple, and fourOf features.\n",
    "pair = [0]*len(df['S1'])\n",
    "triple = [0]*len(df['S1'])\n",
    "fourOf = [0]*len(df['S1'])\n",
    "\n",
    "for i in range(len(df['C1'])):\n",
    "    cards = [df['C1'][i], df['C2'][i], df['C3'][i], df['C4'][i], df['C5'][i]]\n",
    "    cards.sort()\n",
    "    \n",
    "    consec = 0\n",
    "    for j in range(len(cards) - 1):\n",
    "        if cards[j] == cards[j+1]:\n",
    "            if triple[i] > 0 and consec > 0:\n",
    "                triple[i] -= 1\n",
    "                fourOf[i] += 1\n",
    "            elif pair[i] > 0 and consec > 0:\n",
    "                pair[i] -= 1\n",
    "                triple[i] += 1\n",
    "            else:\n",
    "                pair[i] += 1\n",
    "                consec += 1\n",
    "        else:\n",
    "            consec = 0\n",
    "\n",
    "df['pair'] = pair\n",
    "df['triple'] = triple\n",
    "df['fourOf'] = fourOf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding 'straight', 'topStraight' and 'straightFlush' features.\n",
    "straight = [0]*len(df['S1'])\n",
    "\n",
    "for i in range(len(df['S1'])):\n",
    "    temp_list = []\n",
    "    temp_list.append(df['C1'][i])\n",
    "    temp_list.append(df['C2'][i])\n",
    "    temp_list.append(df['C3'][i])\n",
    "    temp_list.append(df['C4'][i])\n",
    "    temp_list.append(df['C5'][i])\n",
    "    temp_list.sort()\n",
    "    \n",
    "    if temp_list[0] != temp_list[1] != temp_list[2] != temp_list[3] != temp_list[4]:\n",
    "        if temp_list[0]+4 == temp_list[4]:\n",
    "            straight[i] = 1\n",
    "        elif temp_list[0] == 1 and temp_list[1] == 10:\n",
    "            straight[i] = 1\n",
    "        else:\n",
    "            straight[i] = 0\n",
    "    else:\n",
    "        straight[i] = 0\n",
    "\n",
    "df['straight'] = straight\n",
    "\n",
    "topStraight = [0]*len(df['S1'])\n",
    "for i in range(len(df['S1'])):\n",
    "    if df['straight'][i] == 1:\n",
    "        values = [df['C1'][i], df['C2'][i], df['C3'][i], df['C4'][i], df['C5'][i]]\n",
    "        if 1 and 13 in values:\n",
    "            topStraight[i] = 1\n",
    "        else:\n",
    "            topStraight[i] = 0\n",
    "    else:\n",
    "        topStraight[i] = 0\n",
    "df['topStraight'] = topStraight\n",
    "\n",
    "straightFlush = [0]*len(df['S1'])\n",
    "for i in range(len(df['S1'])):\n",
    "    if df['flush'][i] == 1 and df['straight'][i] == 1:\n",
    "        straightFlush[i] = 1\n",
    "        \n",
    "df['straightFlush'] = straightFlush"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy using KNN with Cross Validation, Logistical Regression with Cross Validation, and Random Forest with additional features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into training and test sets.\n",
    "X = df[['S1', 'C1', 'S2', 'C2', 'S3', 'C3', 'S4', 'C4', 'S5', 'C5', 'flush', 'pair', 'triple', 'fourOf', 'straight', 'topStraight', 'straightFlush']]\n",
    "y = df['hand']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\sklearn\\model_selection\\_split.py:657: Warning: The least populated class in y has only 8 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6913643563860163\n"
     ]
    }
   ],
   "source": [
    "#KNN\n",
    "#The data set does not contain enough of some of the top end hands, which is the reason for the error.\n",
    "knn = KNeighborsClassifier(n_neighbors=30)\n",
    "knn_accuracy_list = cross_val_score(knn, X, y, cv=10, scoring='accuracy')\n",
    "knn_accuracy_cv = knn_accuracy_list.mean()\n",
    "print(knn_accuracy_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\sklearn\\model_selection\\_split.py:657: Warning: The least populated class in y has only 8 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9731147743804568\n"
     ]
    }
   ],
   "source": [
    "#Logistical Regression\n",
    "#The data set does not contain enough of some of the top end hands, which is the reason for the error.\n",
    "logreg = LogisticRegression(multi_class='auto', solver='liblinear')\n",
    "logreg_accuracy_list = cross_val_score(logreg, X, y, cv=10, scoring = 'accuracy')\n",
    "logreg_accuracy_cv = logreg_accuracy_list.mean()\n",
    "print(logreg_accuracy_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9997348535065623\n",
      "[[3719    0    0    0    0    0    0    0    0    0]\n",
      " [   0 3212    0    0    0    0    0    0    0    0]\n",
      " [   0    0  351    0    0    0    0    0    0    0]\n",
      " [   0    0    0  149    0    0    0    0    0    0]\n",
      " [   0    0    0    0   48    0    0    0    0    0]\n",
      " [   0    0    0    0    0   22    0    0    0    0]\n",
      " [   0    0    0    0    0    0   25    0    0    0]\n",
      " [   0    0    0    0    0    0    0   10    0    0]\n",
      " [   0    0    0    0    0    0    0    0    4    0]\n",
      " [   0    0    0    0    0    0    0    0    2    1]]\n"
     ]
    }
   ],
   "source": [
    "#Random Forest with 70% of the data set as the training set\n",
    "rf = RandomForestClassifier(n_estimators=50, random_state=10)\n",
    "rf.fit(X_train, y_train.values.ravel())\n",
    "rf_y_pred = rf.predict(X_test)\n",
    "rf_accuracy = accuracy_score(rf_y_pred, y_test)\n",
    "print(rf_accuracy)\n",
    "\n",
    "#Confusion Matrix for random forest\n",
    "conf_matrix = confusion_matrix(y_test, rf_y_pred)\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Narrowing features to improve sensitivity for highest ranking hands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Excluding suits and hands, and only leaving the card groupings.\n",
    "X = df[['flush', 'pair', 'triple', 'fourOf', 'straight', 'topStraight', 'straightFlush']]\n",
    "y = df['hand']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\sklearn\\model_selection\\_split.py:657: Warning: The least populated class in y has only 8 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9994430386000305\n"
     ]
    }
   ],
   "source": [
    "#KNN\n",
    "#The data set does not contain enough of some of the top end hands, which is the reason for the error.\n",
    "knn = KNeighborsClassifier(n_neighbors=30)\n",
    "knn_accuracy_list = cross_val_score(knn, X, y, cv=10, scoring='accuracy')\n",
    "knn_accuracy_cv = knn_accuracy_list.mean()\n",
    "print(knn_accuracy_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\sklearn\\model_selection\\_split.py:657: Warning: The least populated class in y has only 8 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9518353772698045\n"
     ]
    }
   ],
   "source": [
    "#Logistical Regression\n",
    "#The data set does not contain enough of some of the top end hands, which is the reason for the error.\n",
    "logreg = LogisticRegression(multi_class='auto', solver='liblinear')\n",
    "logreg_accuracy_list = cross_val_score(logreg, X, y, cv=10, scoring = 'accuracy')\n",
    "logreg_accuracy_cv = logreg_accuracy_list.mean()\n",
    "print(logreg_accuracy_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "[[3719    0    0    0    0    0    0    0    0    0]\n",
      " [   0 3212    0    0    0    0    0    0    0    0]\n",
      " [   0    0  351    0    0    0    0    0    0    0]\n",
      " [   0    0    0  149    0    0    0    0    0    0]\n",
      " [   0    0    0    0   48    0    0    0    0    0]\n",
      " [   0    0    0    0    0   22    0    0    0    0]\n",
      " [   0    0    0    0    0    0   25    0    0    0]\n",
      " [   0    0    0    0    0    0    0   10    0    0]\n",
      " [   0    0    0    0    0    0    0    0    4    0]\n",
      " [   0    0    0    0    0    0    0    0    0    3]]\n"
     ]
    }
   ],
   "source": [
    "#Random Forest with 70% of the data set as the training set\n",
    "rf = RandomForestClassifier(n_estimators=50, random_state=10)\n",
    "rf.fit(X_train, y_train.values.ravel())\n",
    "rf_y_pred = rf.predict(X_test)\n",
    "rf_accuracy = accuracy_score(rf_y_pred, y_test)\n",
    "print(rf_accuracy)\n",
    "\n",
    "#Confusion Matrix for random forest\n",
    "conf_matrix = confusion_matrix(y_test, rf_y_pred)\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
